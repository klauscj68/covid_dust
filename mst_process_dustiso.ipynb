{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "376d571b",
   "metadata": {},
   "source": [
    "# Processing of dust data with individual isolation movement\n",
    "This notebook processes the several data streams needed to run calibration of dust shedding hyperparameters on Spring 2022 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6153dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV,DataFrames,Plots,Measures,Dates\n",
    "gr();\n",
    "\n",
    "ENV[\"COLUMNS\"]=10000;\n",
    "ENV[\"LINES\"] = 500;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b55623c",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths the csv files storing Karen's dust collection data\n",
    "#  Naming convention should be \"MmmDd.csv\" to match myparsedustfname routine below\n",
    "fdust = [\"\"];\n",
    "\n",
    "# Goldstar test file path\n",
    "fgdstr = \"\";\n",
    "\n",
    "# File paths to Chance's spreadsheets for students moving in and out of isolation and bld test compliance\n",
    "fiso = \"\";\n",
    "fcmpl = \"\";\n",
    "\n",
    "# Date ranges for which dust is collected\n",
    "day0 = Date(\"2022-01-10\");\n",
    "dayf = Date(\"2022-01-17\");\n",
    "\n",
    "# Days after dayf a later tested positive individual is considered to have contributed to this interval's shedding\n",
    "daywin = Day(5);\n",
    "\n",
    "# Buildings considered for independent dust measurement calibration\n",
    "blds = [\"\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed963b0f",
   "metadata": {},
   "source": [
    "## Ancillary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9624501",
   "metadata": {},
   "source": [
    "As dust data spreadsheets come to have additional month names and associated dates, myparsedustfname may need to be updated below to account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca318b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "function dtrg(v)\n",
    "    day0 = Date(\"3000-01-01\"); dayf = Date(\"0000-01-01\");\n",
    "    for i=1:length(v)\n",
    "        if !ismissing(v[i])\n",
    "            v0 =  Date(v[i],\"m/d/yyyy\")\n",
    "            day0 = v0 < day0 ? v0 : day0;\n",
    "            \n",
    "            dayf = v0 > dayf ? v0 : dayf;\n",
    "        end\n",
    "    end\n",
    "    day0 = day0 == Date(\"3000-01-01\") ? missing : day0;\n",
    "    dayf = dayf == Date(\"0000-01-01\") ? missing : dayf;\n",
    "    return day0,dayf\n",
    "end;\n",
    "\n",
    "function myparsebeg(v)\n",
    "    return dtrg(v)[1];\n",
    "end\n",
    "\n",
    "function myparseend(v)\n",
    "    return dtrg(v)[2];\n",
    "end; \n",
    "\n",
    "function myuppercase(v)\n",
    "    if ismissing(v)\n",
    "        return v\n",
    "    end\n",
    "    return uppercase(v)\n",
    "end;\n",
    "\n",
    "function mysplit(s::String)\n",
    "    w=split(s,\" \")[1]|>Date;\n",
    "    return w\n",
    "end;\n",
    "\n",
    "function myparsedustfname(s::String)\n",
    "    dt = s[4:5];\n",
    "    if s[1:3]==\"Jan\"\n",
    "        mth = \"01\";\n",
    "    elseif s[1:3]==\"Feb\"\n",
    "        mth = \"02\";\n",
    "    elseif s[1:3]==\"Mar\"\n",
    "        mth = \"03\";\n",
    "    end\n",
    "    \n",
    "    return Date(\"2022-\"*mth*\"-\"*dt)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "Used to extract residential buildings from dorm entries of goldstar\n",
    "\"\"\"\n",
    "function ressplit(s::Union{String,Missing})\n",
    "    if ismissing(s)\n",
    "        return s\n",
    "    end\n",
    "    val = split(s,\" - \");\n",
    "    return convert(String,val[2])\n",
    "    end;\n",
    "    \n",
    "function btwn(x::Date,d1::Date,d2::Date)\n",
    "    return (x>=d1)&&(x<=d2)\n",
    "end;\n",
    "\n",
    "\"\"\"\n",
    "Used to map an iso start date into the range of Chance's dust compliance\n",
    "\"\"\"\n",
    "function isocmplymap(drm::String,dt::Date,df::DataFrame)\n",
    "    gdf = groupby(df,\"dorm\");\n",
    "    dftemp = gdf[(dorm=drm,)] |> DataFrame;\n",
    "    sort!(dftemp,\"end_date\"); dts = dftemp[:,\"end_date\"];\n",
    "    n = nrow(dftemp);\n",
    "    \n",
    "    dts = [dts[1]-Day(7);dts[:]];\n",
    "    n+=1;\n",
    "    \n",
    "    @inbounds for i=1:n-1\n",
    "        if (dt>dts[i])&&(dt<=dts[i+1])\n",
    "            return dts[i+1]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return missing\n",
    "end\n",
    "function isocmplymap(drm::Vector{String},dt::Vector{Date},df::DataFrame)\n",
    "    n = length(drm);\n",
    "    return [isocmplymap(drm[i],dt[i],df) for i=1:n]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55a93a",
   "metadata": {},
   "source": [
    "## Process dust sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build master dataframe for Karen's dust sheets\n",
    "dfdustorg = similar(CSV.read(fdust[1],DataFrame),0); dfdustorg[!,\"fname\"] = [] |> (x->convert(Vector{String},x))\n",
    "for fname in fdust\n",
    "    dftemp = CSV.read(fname,DataFrame); dftemp[\"fname\"]=fill(fname,nrow(dftemp));\n",
    "    dfdustorg = vcat(dfdustorg,dftemp,cols=:union);\n",
    "end\n",
    "dfdustorg[!,:Building]=myuppercase.(dfdustorg[!,:Building]);\n",
    "dfdust = dropmissing(dfdustorg,[\"Building\",\"Result\"]); gdf = groupby(dfdust,[\"Building\",\"fname\"]);\n",
    "dfdust = combine(gdf,\"Start Date\"=>myparsebeg=>\"Start Date\",\n",
    "                 \"Result\"=>sum=>\"Result (cp/mg)\",\n",
    "                 \"End Date\"=>myparseend=>\"End Date\",\n",
    "                 \"fname\"=>(x->myparsedustfname.(x))=>\"File Date\");\n",
    "select!(dfdust,[\"Building\",\"Start Date\",\"End Date\",\"File Date\",\"Result (cp/mg)\"]); sort!(dfdust,[\"Building\",\"File Date\"]);\n",
    "rename!(dfdust,[\"Start Date\"=>\"Dust Clct Start\",\"End Date\"=>\"Dust Clct End\"]);\n",
    "dfdust = unique(dfdust);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb58f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Building dust signal:\")\n",
    "dfdust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489085a1",
   "metadata": {},
   "source": [
    "## Process Goldstar and Iso/Bld compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmst = CSV.read(fgdstr,DataFrame); \n",
    "select!(dfmst,Not(\"name_n\")); dropmissing!(dfmst,[\"emplid\",\"test_dt\",\"result_dt\",\"campus\",\"general_affil\"]);\n",
    "dfmst[!,\"test_dt\"] = mysplit.(dfmst[!,\"test_dt\"]);\n",
    "dfmst[!,\"result_dt\"] = mysplit.(dfmst[!,\"result_dt\"]);\n",
    "flag = (  (dfmst[!,\"test_dt\"].>=Date(\"2022-01-10\")).*(dfmst[!,\"result_dt\"].>=Date(\"2022-01-10\"))\n",
    "           .*(dfmst[!,\"campus\"].==\"COL\").*(dfmst[!,\"general_affil\"].==\"STUDENT\")  );\n",
    "dfmst=dfmst[flag,:]; \n",
    "select!(dfmst,[\"emplid\",\"test_dt\",\"result_dt\",\"result\",\"addr_typ\",\"addr_1\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "first(dfmst,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32237ee1",
   "metadata": {},
   "source": [
    "#### Filter to just on campus population and positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c566d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = groupby(dfmst,[\"addr_typ\",\"result\"]);\n",
    "dfoncmp = gdf[(addr_typ=\"DORM\",result=\"DETECTED\")]|>DataFrame;\n",
    "dfoncmp[!,\"addr_1\"] = ressplit.(dfoncmp[!,\"addr_1\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce651fda",
   "metadata": {},
   "source": [
    "#### Print the names of campus buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(dfoncmp[!,\"addr_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6312096",
   "metadata": {},
   "source": [
    "### Extract isolation movement and building compliance from Chance's output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577ef42",
   "metadata": {},
   "source": [
    "#### Individual traffic for the relevant date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiso = CSV.read(fiso,DataFrame); select!(dfiso,Not([\"Column1\",\"order_location\",\"dorm_building\"]));\n",
    "dropmissing!(dfiso,\"start_date\"); #flag = dfchance[!,\"start_date\"].>=Date(\"2022-01-10\"); dfchance = dfchance[flag,:];\n",
    "rename!(dfiso,[\"start_date\"=>\"isostart_date\",\"release_date\"=>\"isorelease_date\"])\n",
    "transform!(dfiso,\"isostart_date\"=>(x->(x.-Date(\"2022-01-10\")))=>\"isostart_day_relJan10\");\n",
    "dfindiv = leftjoin(dfoncmp,dfiso,on=:emplid);\n",
    "\n",
    "# If isostart missing, assume it's one day after the result date\n",
    "flag = ismissing.(dfindiv[!,\"isostart_date\"]); \n",
    "dfindiv[flag,\"isostart_date\"] = dfindiv[flag,\"result_dt\"].+Day(1); dropmissing!(dfindiv,\"isostart_date\");\n",
    "\n",
    "# Filter to the relevant date ranges\n",
    "flag=(dfindiv[!,\"isostart_date\"].>=day0).*(dfindiv[!,\"isostart_date\"].<=dayf+daywin);\n",
    "println(\"Test positive individuals in all buildings moving into isolation during from $day0 to $daywin after $dayf\");\n",
    "dfindiv=dfindiv[flag,:];sort!(dfindiv,[\"addr_1\",\"isostart_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35817de8",
   "metadata": {},
   "source": [
    "#### Extract building compliance from Chance\n",
    "Confirm with Chance that we should use an end date over a start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58cdea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine Chance's compliance spreadsheet\n",
    "dfcmpl = CSV.read(fcmpl,DataFrame); select!(dfcmpl,Not(\"Column1\")); dropmissing!(dfcmpl,\"dorm\");\n",
    "transform!(dfcmpl,\"start_date\"=>(x->x.+Day(7))=>\"end_date\");\n",
    "transform!(dfcmpl,[\"n_compliant\",\"n_to_test\"]=>((x,y)->x./y)=>\"compliance\"); sort!(dfcmpl,[\"dorm\",\"end_date\"]);\n",
    "select!(dfcmpl,[\"dorm\",\"end_date\",\"n_to_test\",\"compliance\"]);\n",
    "\n",
    "# Filter to relevant date ranges\n",
    "flag = (dfcmpl[!,\"end_date\"].>day0).*(dfcmpl[!,\"end_date\"].<=dayf);\n",
    "println(\"Campus compliance across all buildings from ($day0,$dayf]\")\n",
    "dfcmpl = dfcmpl[flag,:]; sort!(dfcmpl,[\"dorm\",\"end_date\"]);\n",
    "dfcmpl = leftjoin(dfcmpl,dfdust,on=[\"dorm\"=>\"Building\",\"end_date\"=>\"File Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Campus compliance summary statistics:\")\n",
    "gdf = groupby(dfcmpl,\"end_date\");\n",
    "dfcmpl_sum = combine(gdf,\"compliance\"=>(x->sum(x)/length(x))=>\"mean campus compliance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d8063",
   "metadata": {},
   "source": [
    "#### Restrict to the relevant buildings for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process individuals\n",
    "gdf = groupby(dfindiv,[\"addr_1\"]); dftemp = similar(dfindiv,0);\n",
    "for bld in blds\n",
    "    key = (addr_1=bld,);\n",
    "    dftemp = vcat(dftemp,(gdf[key] |> DataFrame));\n",
    "end\n",
    "dfindiv = deepcopy(dftemp);\n",
    "\n",
    "# Process compliance\n",
    "gdf = groupby(dfcmpl,[\"dorm\"]); dftemp = similar(dfcmpl,0);\n",
    "for bld in blds\n",
    "    key = (dorm=bld,);\n",
    "    dftemp = vcat(dftemp,(gdf[key] |> DataFrame));\n",
    "end\n",
    "dfcmpl = deepcopy(dftemp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Test positive individuals in specified buildings moving into isolation from [$day0,$dayf+$daywin]:\")\n",
    "dfindiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ed3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Campus compliance in specified buildings from ($day0,$dayf]:\")\n",
    "dfcmpl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a7168",
   "metadata": {},
   "source": [
    "#### Renormalize according to compliance for additional number of infected in the building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join individual information with compliance data\n",
    "transform!(dfindiv,[\"addr_1\",\"test_dt\"]=>((x,y)->isocmplymap(x,y,dfcmpl))=>\"end_date\");\n",
    "dftemp = leftjoin(dfindiv,dfcmpl,on=[\"addr_1\"=>\"dorm\",\"end_date\"=>\"end_date\"]);\n",
    "\n",
    "# Aggregate number of observed infected and extrapolated infected during these time periods\n",
    "gdf = groupby(dftemp,[\"addr_1\",\"end_date\"]);\n",
    "dfagg = combine(gdf,nrow=>\"obs_inf\",\"compliance\"=>(x->x[1])=>\"compl\",\"n_to_test\"=>(x->x[1])=>\"pop\");\n",
    "projinf = (pop,cmp,obsinf)->( (obsinf./(pop.*cmp)).*(1 .-cmp).*pop.+obsinf );\n",
    "transform!(dfagg,[\"pop\",\"compl\",\"obs_inf\"]=>projinf=>\"proj_inf\");\n",
    "dropmissing!(dfagg,[\"end_date\",\"pop\",\"compl\"]);\n",
    "dfagg[!,\"proj_inf\"] = dfagg[!,\"proj_inf\"] |> (x->round.(x)) |> (x->Int64.(x));\n",
    "println(\"Aggregate counts of infected in the buildings during specified date ranges:\")\n",
    "sort!(dfagg,[\"addr_1\",\"end_date\"]);\n",
    "dfagg = leftjoin(dfagg,dfdust,on=[\"addr_1\"=>\"Building\",\"end_date\"=>\"File Date\"])\n",
    "select!(dfagg,[\"addr_1\",\"pop\",\"end_date\",\"compl\",\"obs_inf\",\"proj_inf\",\"Result (cp/mg)\"])\n",
    "CSV.write(\"blddust.csv\",dfagg);\n",
    "dfagg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60f411",
   "metadata": {},
   "source": [
    "## Export Individual infections for these buildings including projected\n",
    "Even though we have included a 5 day window to account for people shedding before they were detected at a later week, we still assume that those people are observed from the compliant population, ie disjoint from the projected infections above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ccd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dictionary with keys giving projected infections based on dfagg table\n",
    "dictpr = Dict{Tuple{String,Date},Int64}();\n",
    "for i=1:nrow(dfagg)\n",
    "    bld = dfagg[i,\"addr_1\"]; dt = dfagg[i,\"end_date\"]; \n",
    "    exinf = dfagg[i,\"proj_inf\"]-dfagg[i,\"obs_inf\"];\n",
    "    dictpr[(bld,dt)]=exinf;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea15ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sick any date before test_dt is t₀\n",
    "# Enter isolation on a isostart_date tℓ\n",
    "# end_date only used for estimating additional infected individuals\n",
    "dftemp = select(dfindiv,[\"addr_1\",\"test_dt\",\"isostart_date\",\"end_date\"]);\n",
    "gdf = groupby(dftemp,[\"addr_1\",\"end_date\"]);\n",
    "\n",
    "dfexp = similar(dftemp,0); day∞ = Date(\"2999-12-31\");\n",
    "for dt in unique(dfcmpl[!,\"end_date\"])\n",
    "    for bld in blds\n",
    "        key = (addr_1=bld,end_date=dt);\n",
    "        local dftemp = gdf[key] |> DataFrame;\n",
    "        # Fill with dummy rows for the projected infections\n",
    "        nnew = dictpr[(bld,dt)];\n",
    "        for n=1:nnew\n",
    "            dfram = Dict(\"addr_1\"=>[bld],\"test_dt\"=>[dt],\"isostart_date\"=>[day∞],\n",
    "                         \"end_date\"=>[day∞]) |> DataFrame;\n",
    "            dftemp = vcat(dftemp,dfram);\n",
    "        end\n",
    "        dfexp = vcat(dfexp,dftemp);\n",
    "    end\n",
    "end\n",
    "for bld in blds\n",
    "    dfexp = vcat(dfexp,DataFrame(gdf[(addr_1=bld,end_date=missing)]));\n",
    "end\n",
    "sort!(dfexp,[\"addr_1\",\"end_date\"]);\n",
    "select!(dfexp,Not(\"end_date\"));\n",
    "\n",
    "# Add indicator columns to say which individuals count for which dust measurements\n",
    "for edt in fdust\n",
    "    sdt = edt[1:5];\n",
    "    dt = myparsedustfname(edt);\n",
    "    \n",
    "    # When handle projected infections localize those to the week they were matched to\n",
    "    dfexp[!,sdt] = [(dfexp[i,\"test_dt\"]>=dt-Day(7))&&(dfexp[i,\"test_dt\"]<=dt+daywin)&&(\n",
    "                     (dfexp[i,\"isostart_date\"]!=day∞)||(dfexp[i,\"test_dt\"]==dt))\n",
    "                    for i=1:nrow(dfexp)];\n",
    "end\n",
    "\n",
    "println(\"Individual infection and isolation data built from compliance and line data:\")\n",
    "println(\"(Note: Projected infections had a Dec 31, 2999 date assigned to isostart and their week assigned to test_dt.)\")\n",
    "dfexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481eb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"indivposbybld.csv\",dfexp);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
